{"cells":[{"cell_type":"markdown","metadata":{"id":"XAVN6c8prKOL"},"source":["##### Copyright 2019 The TensorFlow Authors.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"SassPC7WQAUO"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"KwDK47gfLsYf"},"source":["# Implement Differential Privacy with TensorFlow Privacy"]},{"cell_type":"markdown","metadata":{"id":"MfBg1C5NB3X0"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/responsible_ai/privacy/tutorials/classification_privacy\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/privacy/blob/master/g3doc/tutorials/classification_privacy.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/privacy/blob/master/g3doc/tutorials/classification_privacy.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/privacy/g3doc/tutorials/classification_privacy.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"00fQV7e0Unz3"},"source":["## Overview"]},{"cell_type":"markdown","metadata":{"id":"vsCUvXP0W4j2"},"source":["[Differential privacy](https://en.wikipedia.org/wiki/Differential_privacy) (DP) is a framework for measuring the privacy guarantees provided by an algorithm. Through the lens of differential privacy, you can design machine learning algorithms that responsibly train models on private data. Learning with differential privacy provides measurable guarantees of privacy, helping to mitigate the risk of exposing sensitive training data in machine learning. Intuitively, a model trained with differential privacy should not be affected by any single training example, or small set of training examples, in its data set. This helps mitigate the risk of exposing sensitive training data in ML."]},{"cell_type":"markdown","metadata":{"id":"6vd8qUwEW5pP"},"source":["The basic idea of this approach, called differentially private stochastic gradient descent (DP-SGD), is to modify the gradients\n","used in stochastic gradient descent (SGD), which lies at the core of almost all deep learning algorithms. Models trained with DP-SGD provide provable differential privacy guarantees for their input data. There are two modifications made to the vanilla SGD algorithm:"]},{"cell_type":"markdown","metadata":{"id":"TUphKzYu01O9"},"source":["1. First, the sensitivity of each gradient needs to be bounded. In other words, you need to limit how much each individual training point sampled in a minibatch can influence gradient computations and the resulting updates applied to model parameters. This can be done by *clipping* each gradient computed on each training point.\n","2. *Random noise* is sampled and added to the clipped gradients to make it statistically impossible to know whether or not a particular data point was included in the training dataset by comparing the updates SGD applies when it operates with or without this particular data point in the training dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"jXU7MZhhW-aL"},"source":["This tutorial uses [tf.keras](https://www.tensorflow.org/guide/keras) to train a convolutional neural network (CNN) to recognize handwritten digits with the DP-SGD optimizer provided by the TensorFlow Privacy library. TensorFlow Privacy provides code that wraps an existing TensorFlow optimizer to create a variant that implements DP-SGD."]},{"cell_type":"markdown","metadata":{"id":"ijJYKVc05DYX"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"CKuHPYQCsV-x"},"source":["Begin by importing the necessary libraries:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ef56gCUqrdVn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668155837036,"user_tz":-330,"elapsed":2484,"user":{"displayName":"Sai Amruth Balusu","userId":"03035844597752670558"}},"outputId":"9302858f-1929-4955-94ab-d500fbc4587c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["import tensorflow as tf\n","tf.compat.v1.disable_v2_behavior()\n","\n","import numpy as np\n","\n","tf.get_logger().setLevel('ERROR')"]},{"cell_type":"markdown","metadata":{"id":"r_fVhfUyeI3d"},"source":["Install TensorFlow Privacy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r56BqqyEqA16","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1668155864922,"user_tz":-330,"elapsed":27909,"user":{"displayName":"Sai Amruth Balusu","userId":"03035844597752670558"}},"outputId":"365b930c-1cd8-43da-fe17-c77c78d4bc87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-privacy\n","  Downloading tensorflow_privacy-0.8.7-py3-none-any.whl (301 kB)\n","\u001b[K     |████████████████████████████████| 301 kB 28.8 MB/s \n","\u001b[?25hCollecting attrs~=21.4\n","  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy~=1.21 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.21.6)\n","Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.0.2)\n","Collecting dp-accounting==0.3.0\n","  Downloading dp_accounting-0.3.0-py3-none-any.whl (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: dm-tree==0.1.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.1.7)\n","Collecting matplotlib~=3.3\n","  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[K     |████████████████████████████████| 11.2 MB 43.7 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.3.0)\n","Requirement already satisfied: tensorflow-datasets~=4.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (4.6.0)\n","Collecting tensorflow-probability==0.15.0\n","  Downloading tensorflow_probability-0.15.0-py2.py3-none-any.whl (5.7 MB)\n","\u001b[K     |████████████████████████████████| 5.7 MB 28.9 MB/s \n","\u001b[?25hRequirement already satisfied: scipy~=1.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.7.3)\n","Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.9.2)\n","Requirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.9.0)\n","Collecting tensorflow-privacy\n","  Downloading tensorflow_privacy-0.8.6-py3-none-any.whl (301 kB)\n","\u001b[K     |████████████████████████████████| 301 kB 64.1 MB/s \n","\u001b[?25h  Downloading tensorflow_privacy-0.8.5-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 28.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-probability~=0.15 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.17.0)\n","  Downloading tensorflow_privacy-0.8.4-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 52.1 MB/s \n","\u001b[?25hCollecting pandas~=1.1.4\n","  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 42.9 MB/s \n","\u001b[?25hCollecting matplotlib~=3.3.4\n","  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n","\u001b[K     |████████████████████████████████| 11.5 MB 46.0 MB/s \n","\u001b[?25hCollecting dp-accounting~=0.1.2\n","  Downloading dp_accounting-0.1.2-py3-none-any.whl (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 354 kB/s \n","\u001b[?25hCollecting tensorflow-datasets~=4.5.2\n","  Downloading tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 48.9 MB/s \n","\u001b[?25hCollecting absl-py~=1.0.0\n","  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n","\u001b[K     |████████████████████████████████| 126 kB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py~=1.0.0->tensorflow-privacy) (1.15.0)\n","Requirement already satisfied: mpmath~=1.2.1 in /usr/local/lib/python3.7/dist-packages (from dp-accounting~=0.1.2->tensorflow-privacy) (1.2.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (7.1.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib~=3.3.4->tensorflow-privacy) (4.1.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.4->tensorflow-privacy) (2022.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy) (3.1.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.1.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (57.4.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.9.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.50.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (21.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.27.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.6.3)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.12)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.19.6)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (14.0.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow-privacy) (0.38.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.4->tensorflow-privacy) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2.14.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (5.2.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.2.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (4.64.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (0.3.6)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (5.10.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15->tensorflow-privacy) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15->tensorflow-privacy) (1.5.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.56.4)\n","Installing collected packages: absl-py, attrs, tensorflow-datasets, pandas, matplotlib, dp-accounting, tensorflow-privacy\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.3.0\n","    Uninstalling absl-py-1.3.0:\n","      Successfully uninstalled absl-py-1.3.0\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 22.1.0\n","    Uninstalling attrs-22.1.0:\n","      Successfully uninstalled attrs-22.1.0\n","  Attempting uninstall: tensorflow-datasets\n","    Found existing installation: tensorflow-datasets 4.6.0\n","    Uninstalling tensorflow-datasets-4.6.0:\n","      Successfully uninstalled tensorflow-datasets-4.6.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","Successfully installed absl-py-1.0.0 attrs-21.4.0 dp-accounting-0.1.2 matplotlib-3.3.4 pandas-1.1.5 tensorflow-datasets-4.5.2 tensorflow-privacy-0.8.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["absl","matplotlib","mpl_toolkits","pandas"]}}},"metadata":{}}],"source":["!pip install tensorflow-privacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RseeuA7veIHU"},"outputs":[],"source":["import tensorflow_privacy\n","\n","from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy"]},{"cell_type":"markdown","metadata":{"id":"mU1p8N7M5Mmn"},"source":["## Load and pre-process the dataset\n","\n","Load the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and prepare the data for training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1ML23FlueTr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668155868965,"user_tz":-330,"elapsed":3221,"user":{"displayName":"Sai Amruth Balusu","userId":"03035844597752670558"}},"outputId":"1bdee34e-726a-4f4e-d924-159b623470c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n"]}],"source":["train, test = tf.keras.datasets.mnist.load_data()\n","train_data, train_labels = train\n","test_data, test_labels = test\n","\n","train_data = np.array(train_data, dtype=np.float32) / 255\n","test_data = np.array(test_data, dtype=np.float32) / 255\n","\n","train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n","test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n","\n","train_labels = np.array(train_labels, dtype=np.int32)\n","test_labels = np.array(test_labels, dtype=np.int32)\n","\n","train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n","test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n","\n","assert train_data.min() == 0.\n","assert train_data.max() == 1.\n","assert test_data.min() == 0.\n","assert test_data.max() == 1."]},{"cell_type":"markdown","metadata":{"id":"xVDcswOCtlr3"},"source":["## Define the hyperparameters\n","Set learning model hyperparamter values. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E14tL1vUuTRV"},"outputs":[],"source":["epochs = 3\n","batch_size = 250"]},{"cell_type":"markdown","metadata":{"id":"qXNp_25y7JP2"},"source":["DP-SGD has three privacy-specific hyperparameters and one existing hyperamater that you must tune:\n","\n","1. `l2_norm_clip` (float) - The maximum Euclidean (L2) norm of each gradient that is applied to update model parameters. This hyperparameter is used to bound the optimizer's sensitivity to individual training points. \n","2. `noise_multiplier` (float) - The amount of noise sampled and added to gradients during training. Generally, more noise results in better privacy (often, but not necessarily, at the expense of lower utility).\n","3.   `microbatches` (int) - Each batch of data is split in smaller units called microbatches. By default, each microbatch should contain a single training example. This allows us to clip gradients on a per-example basis rather than after they have been averaged across the minibatch. This in turn decreases the (negative) effect of clipping on signal found in the gradient and typically maximizes utility. However, computational overhead can be reduced by increasing the size of microbatches to include more than one training examples. The average gradient across these multiple training examples is then clipped. The total number of examples consumed in a batch, i.e., one step of gradient descent, remains the same. The number of microbatches should evenly divide the batch size. \n","4. `learning_rate` (float) - This hyperparameter already exists in vanilla SGD. The higher the learning rate, the more each update matters. If the updates are noisy (such as when the additive noise is large compared to the clipping threshold), a low learning rate may help the training procedure converge. \n","\n","Use the hyperparameter values below to obtain a reasonably accurate model (95% test accuracy):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVw_r2Mq7ntd"},"outputs":[],"source":["l2_norm_clip = 1.5\n","noise_multiplier = 1.3\n","num_microbatches = 250\n","learning_rate = 0.25\n","\n","if batch_size % num_microbatches != 0:\n","  raise ValueError('Batch size should be an integer multiple of the number of microbatches')"]},{"cell_type":"markdown","metadata":{"id":"wXAmHcNOmHc5"},"source":["## Build the model\n","\n","Define a convolutional neural network as the learning model. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCOo8aOLmFta"},"outputs":[],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(16, 8,\n","                           strides=2,\n","                           padding='same',\n","                           activation='relu',\n","                           input_shape=(28, 28, 1)),\n","    tf.keras.layers.MaxPool2D(2, 1),\n","    tf.keras.layers.Conv2D(32, 4,\n","                           strides=2,\n","                           padding='valid',\n","                           activation='relu'),\n","    tf.keras.layers.MaxPool2D(2, 1),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(10)\n","])"]},{"cell_type":"markdown","metadata":{"id":"FT4lByFg-I_r"},"source":["Define the optimizer and loss function for the learning model. Compute the loss as a vector of losses per-example rather than as the mean over a minibatch to support gradient manipulation over each training point. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqBvjCf5-ZXy"},"outputs":[],"source":["optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n","    l2_norm_clip=l2_norm_clip,\n","    noise_multiplier=noise_multiplier,\n","    num_microbatches=num_microbatches,\n","    learning_rate=learning_rate)\n","\n","loss = tf.keras.losses.CategoricalCrossentropy(\n","    from_logits=True, reduction=tf.losses.Reduction.NONE)"]},{"cell_type":"markdown","metadata":{"id":"LI_3nXzEGmrP"},"source":["## Train the model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z4iV03VqG1Bo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668156136330,"user_tz":-330,"elapsed":267423,"user":{"displayName":"Sai Amruth Balusu","userId":"03035844597752670558"}},"outputId":"34458fce-8d66-4089-9c6d-611112d0c346"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/3\n","60000/60000 [==============================] - ETA: 0s - loss: 1.0619 - acc: 0.6741"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 82s 1ms/sample - loss: 1.0619 - acc: 0.6741 - val_loss: 0.5166 - val_acc: 0.8424\n","Epoch 2/3\n","60000/60000 [==============================] - 60s 1ms/sample - loss: 0.4878 - acc: 0.8696 - val_loss: 0.4019 - val_acc: 0.9019\n","Epoch 3/3\n","60000/60000 [==============================] - 61s 1ms/sample - loss: 0.4216 - acc: 0.9015 - val_loss: 0.3811 - val_acc: 0.9197\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff00b71ef10>"]},"metadata":{},"execution_count":10}],"source":["model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","\n","model.fit(train_data, train_labels,\n","          epochs=epochs,\n","          validation_data=(test_data, test_labels),\n","          batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"0kkzQH2LXNjF"},"source":["## Measure the differential privacy guarantee\n","\n","Perform a privacy analysis to measure the DP guarantee achieved by a training algorithm. Knowing the level of DP achieved enables the objective comparison of two training runs to determine which of the two is more privacy-preserving. At a high level, the privacy analysis measures how much a potential adversary can improve their guess about properties of any individual training point by observing the outcome of the training procedure (e.g., model updates and parameters). \n"]},{"cell_type":"markdown","metadata":{"id":"TL7_lX5sHCTI"},"source":["This guarantee is sometimes referred to as the **privacy budget**. A lower privacy budget bounds more tightly an adversary's ability to improve their guess. This ensures a stronger privacy guarantee. Intuitively, this is because it is harder for a single training point to affect the outcome of learning: for instance, the information contained in the training point cannot be memorized by the ML algorithm and the privacy of the individual who contributed this training point to the dataset is preserved.\n","\n","In this tutorial, the privacy analysis is performed in the framework of Rényi Differential Privacy (RDP), which is a relaxation of pure DP based on [this paper](https://arxiv.org/abs/1702.07476) that is particularly well suited for DP-SGD.\n"]},{"cell_type":"markdown","metadata":{"id":"wUEk25pgmnm-"},"source":["Two metrics are used to express the DP guarantee of an ML algorithm:\n","\n","1.   Delta ($\\delta$) - Bounds the probability of the privacy guarantee not holding. A rule of thumb is to set it to be less than the inverse of the size of the training dataset. In this tutorial, it is set to **10^-5** as the MNIST dataset has 60,000 training points.\n","2.   Epsilon ($\\epsilon$) - This is the privacy budget. It measures the strength of the privacy guarantee by bounding how much the probability of a particular model output can vary by including (or excluding) a single training point. A smaller value for $\\epsilon$ implies a better privacy guarantee. However, the $\\epsilon$ value is only an upper bound and a large value could still mean good privacy in practice."]},{"cell_type":"markdown","metadata":{"id":"PczVdKsGyRQM"},"source":["Tensorflow Privacy provides a tool, `compute_dp_sgd_privacy`, to compute the value of $\\epsilon$ given a fixed value of $\\delta$ and the following hyperparameters from the training process:\n","\n","1.   The total number of points in the training data, `n`.\n","2. The `batch_size`.\n","3.   The `noise_multiplier`.\n","4. The number of `epochs` of training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ws8-nVuVDgtJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668156136331,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sai Amruth Balusu","userId":"03035844597752670558"}},"outputId":"6ce03a8d-2ae3-4c28-929e-126d2f7b1218"},"outputs":[{"output_type":"stream","name":"stdout","text":["DP-SGD with sampling rate = 0.417% and noise_multiplier = 1.3 iterated over 720 steps satisfies differential privacy with eps = 0.563 and delta = 1e-05.\n","The optimal RDP order is 18.0.\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.5631726490328062, 18.0)"]},"metadata":{},"execution_count":11}],"source":["compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=train_data.shape[0],\n","                                              batch_size=batch_size,\n","                                              noise_multiplier=noise_multiplier,\n","                                              epochs=epochs,\n","                                              delta=1e-5)"]},{"cell_type":"markdown","metadata":{"id":"c-KyttEWFRDc"},"source":["The tool reports that for the hyperparameters chosen above, the trained model has an $\\epsilon$ value of 1.18."]},{"cell_type":"markdown","metadata":{"id":"SA_9HMGBWFM3"},"source":["## Summary\n","In this tutorial, you learned about differential privacy (DP) and how you can implement DP principles in existing ML algorithms to provide privacy guarantees for training data. In particular, you learned how to:\n","*   Wrap existing optimizers (e.g., SGD, Adam) into their differentially private counterparts using TensorFlow Privacy\n","*   Tune hyperparameters introduced by differentially private machine learning\n","*   Measure the privacy guarantee provided using analysis tools included in TensorFlow Privacy"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/tensorflow/privacy/blob/master/g3doc/tutorials/classification_privacy.ipynb","timestamp":1668155273462}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}