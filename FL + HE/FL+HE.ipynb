{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install tensorflow-privacy"],"metadata":{"id":"Sd2VZnfB8-Ot"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyQZBaxK2OjF","outputId":"edbdfc48-6b4f-430d-9778-2992f0a749f7","executionInfo":{"status":"ok","timestamp":1667198735557,"user_tz":-330,"elapsed":4412,"user":{"displayName":"saif kamalsha","userId":"01138243331887387772"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting phe\n","  Downloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n","\u001b[?25hInstalling collected packages: phe\n","Successfully installed phe-1.5.0\n"]}],"source":["pip install phe"]},{"cell_type":"code","source":["# Import Dependencies\n","import numpy as np\n","from sklearn.datasets import load_diabetes\n","import phe as paillier\n","import random"],"metadata":{"id":"Qb4Apk6vjHXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Description\n","diabetes = load_diabetes()\n","print(diabetes['DESCR'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VErnvYl-pgiw","outputId":"05be5006-a344-446f-c42a-64c73adada71","executionInfo":{"status":"ok","timestamp":1667198745582,"user_tz":-330,"elapsed":3,"user":{"displayName":"saif kamalsha","userId":"01138243331887387772"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _diabetes_dataset:\n","\n","Diabetes dataset\n","----------------\n","\n","Ten baseline variables, age, sex, body mass index, average blood\n","pressure, and six blood serum measurements were obtained for each of n =\n","442 diabetes patients, as well as the response of interest, a\n","quantitative measure of disease progression one year after baseline.\n","\n","**Data Set Characteristics:**\n","\n","  :Number of Instances: 442\n","\n","  :Number of Attributes: First 10 columns are numeric predictive values\n","\n","  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n","\n","  :Attribute Information:\n","      - age     age in years\n","      - sex\n","      - bmi     body mass index\n","      - bp      average blood pressure\n","      - s1      tc, total serum cholesterol\n","      - s2      ldl, low-density lipoproteins\n","      - s3      hdl, high-density lipoproteins\n","      - s4      tch, total cholesterol / HDL\n","      - s5      ltg, possibly log of serum triglycerides level\n","      - s6      glu, blood sugar level\n","\n","Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n","\n","Source URL:\n","https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n","\n","For more information see:\n","Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n","(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"]}]},{"cell_type":"code","source":["# Function to Get the Data\n","def get_data(n_clients):\n","    \"\"\"\n","    Import the dataset via sklearn, shuffle and split train/test.\n","    Return training, target lists for `n_clients` and a holdout test set\n","    \"\"\"\n","    print(\"Loading data\")\n","    diabetes = load_diabetes()\n","    y = diabetes.target\n","    X = diabetes.data\n","\n","    # Adding constant to emulate intercept\n","    X = np.c_[X, np.ones(X.shape[0])]\n","\n","    \n","    # Shuffle\n","    perm = np.random.permutation(X.shape[0])\n","    X, y = X[perm, :], y[perm]\n","\n","    # Select test at random\n","    test_size = 50\n","    test_idx = np.random.choice(X.shape[0], size=test_size, replace=False)\n","    train_idx = np.ones(X.shape[0], dtype=bool)\n","    train_idx[test_idx] = False\n","    X_test, y_test = X[test_idx, :], y[test_idx]\n","    X_train, y_train = X[train_idx, :], y[train_idx]\n","\n","    # Spliting train among multiple clients.\n","    X, y = [], []\n","    step = int(X_train.shape[0] / n_clients)\n","    for c in range(n_clients):\n","        X.append(X_train[step * c: step * (c + 1), :])\n","        y.append(y_train[step * c: step * (c + 1)])\n","\n","    return X, y, X_test, y_test"],"metadata":{"id":"Vq90BO8W2Psa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MSE for Linear Regression\n","def mean_square_error(y_pred, y):\n","    \"\"\" 1/m * \\sum_{i=1..m} (y_pred_i - y_i)^2 \"\"\"\n","    return np.mean((y - y_pred) ** 2)"],"metadata":{"id":"C7yi8bSyjZ97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to take in the Public Key and Encrypt the Data\n","def encrypt_vector(public_key, x):\n","    return [public_key.encrypt(i) for i in x]"],"metadata":{"id":"zCQwh4gjjcxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to take in the Private key and Decrypt the Data\n","def decrypt_vector(private_key, x):\n","    return np.array([private_key.decrypt(i) for i in x])"],"metadata":{"id":"xSHm-bX0jfKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to Sum up the Encrypted Values\n","def sum_encrypted_vectors(x, y):\n","    if len(x) != len(y):\n","        raise ValueError('Encrypted vectors must have the same size')\n","    return [x[i] + y[i] for i in range(len(x))]"],"metadata":{"id":"BgFu2k_3jivL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SERVER"],"metadata":{"id":"iMAAVt-bvNxJ"}},{"cell_type":"code","source":["class Server:\n","    \"\"\"Private key holder. Decrypts the average gradient\"\"\"\n","\n","    def __init__(self, key_length):\n","        keypair = paillier.generate_paillier_keypair(n_length=key_length)\n","        self.pubkey, self.privkey = keypair\n","\n","    def decrypt_aggregate(self, input_model, n_clients):\n","        return decrypt_vector(self.privkey, input_model) / n_clients"],"metadata":{"id":"UR6TdQfGjmV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["CLIENT"],"metadata":{"id":"LPay_jBAvQTW"}},{"cell_type":"code","source":["class Client:\n","    \"\"\"Runs linear regression with local data or by gradient steps,\n","    where gradient can be passed in.\n","    Using public key can encrypt locally computed gradients.\n","    \"\"\"\n","\n","    def __init__(self, name, X, y, pubkey):\n","        self.name = name\n","        self.pubkey = pubkey\n","        self.X, self.y = X, y\n","        self.weights = np.zeros(X.shape[1])\n","\n","    def fit(self, n_iter, eta=0.01):\n","        \"\"\"Linear regression for n_iter\"\"\"\n","        for _ in range(n_iter):\n","            gradient = self.compute_gradient()\n","            self.gradient_step(gradient, eta)\n","\n","    def gradient_step(self, gradient, eta=0.01):\n","        \"\"\"Updating the model with the given gradient\"\"\"\n","        self.weights -= eta * gradient\n","\n","    def compute_gradient(self):\n","        \"\"\"Computing the gradient of the current model using the training set\n","        \"\"\"\n","        delta = self.predict(self.X) - self.y\n","        return delta.dot(self.X);\n","        #return delta.dot(self.X) + random.random();\n","\n","    def predict(self, X):\n","        return X.dot(self.weights)\n","\n","    def encrypted_gradient(self, sum_to=None):\n","        \"\"\"Computing and encrypt gradient.\"\"\"\n","        gradient = self.compute_gradient()\n","        encrypted_gradient = encrypt_vector(self.pubkey,gradient)\n","        if sum_to is not None:\n","            return sum_encrypted_vectors(sum_to, encrypted_gradient)\n","        else:\n","            return encrypted_gradient"],"metadata":{"id":"jJcE2uNmjpMC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FEDERATED LEARNING"],"metadata":{"id":"qOaGbpVOvSMX"}},{"cell_type":"code","source":["def federated_learning(n_iter, eta, n_clients, key_length):\n","    names = ['Hospital {}'.format(i) for i in range(1, n_clients + 1)]\n","\n","    X, y, X_test, y_test = get_data(n_clients=n_clients)\n","\n","    # Instantiating the server and generating private and public keys\n","    server = Server(key_length=key_length)\n","\n","    # Instantiating the clients.\n","    clients = []\n","    for i in range(n_clients):\n","        clients.append(Client(names[i], X[i], y[i], server.pubkey))\n","    print('Error (MSE) that each client gets on test set by '\n","          'training only on own local data:')\n","    for c in clients:\n","        c.fit(n_iter, eta)\n","        y_pred = c.predict(X_test)\n","        mse = mean_square_error(y_pred, y_test)\n","        print('{:s}:\\t{:.2f}'.format(c.name, mse))\n","\n","    # The federated learning with gradient descent\n","    print('Running distributed gradient aggregation for {:d} iterations'\n","          .format(n_iter))\n","    for i in range(n_iter):\n","\n","        # Computing gradients, encrypting and aggregating\n","        encrypt_aggr = clients[0].encrypted_gradient(sum_to=None)\n","        for c in clients:\n","            encrypt_aggr = c.encrypted_gradient(sum_to=encrypt_aggr)\n","\n","        # Sending aggregate to server and decrypt it\n","        aggr = server.decrypt_aggregate(encrypt_aggr, n_clients)\n","\n","        # Take gradient steps\n","        for c in clients:\n","            c.gradient_step(aggr, eta)\n","\n","    print('Error (MSE) that each client gets after running the protocol:')\n","    for c in clients:\n","        y_pred = c.predict(X_test)\n","        mse = mean_square_error(y_pred, y_test)\n","        print('{:s}:\\t{:.2f}'.format(c.name, mse))"],"metadata":{"id":"OEhumk8djsk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["federated_learning(n_iter=100, eta=0.01, n_clients=3, key_length=1024)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fE1-oyMmjxSG","outputId":"add24df3-5316-4489-d71d-b047c6d46853","executionInfo":{"status":"ok","timestamp":1667199325181,"user_tz":-330,"elapsed":82043,"user":{"displayName":"saif kamalsha","userId":"01138243331887387772"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data\n","Error (MSE) that each client gets on test set by training only on own local data:\n","Hospital 1:\t2992.43\n","Hospital 2:\t2906.90\n","Hospital 3:\t3158.22\n","Running distributed gradient aggregation for 100 iterations\n","Error (MSE) that each client gets after running the protocol:\n","Hospital 1:\t2606.76\n","Hospital 2:\t2594.13\n","Hospital 3:\t2679.82\n"]}]},{"cell_type":"code","source":[" "],"metadata":{"id":"PGoS3gaIl-pU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fvLz-EpPGZCj"},"execution_count":null,"outputs":[]}]}